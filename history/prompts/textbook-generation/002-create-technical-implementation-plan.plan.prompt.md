---
id: 002
title: Create Technical Implementation Plan
stage: plan
date: 2025-12-06
surface: agent
model: claude-sonnet-4-5-20250929
feature: textbook-generation
branch: master
user: user
command: /sp.plan
labels: ["planning", "architecture", "docusaurus", "fastapi", "rag", "technical-design"]
links:
  spec: specs/textbook-generation/spec.md
  ticket: null
  adr: null
  pr: null
files:
  - specs/textbook-generation/plan.md
tests:
  - none
---

## Prompt

/sp.plan

Objective: Create a complete technical plan for the project aligned with business requirements and verified against **Docusaurus Context 7 MCP** (https://docusaurus.io/docs).

1. Architecture Sketch:
   - High-level system architecture: Frontend, Backend, Database, APIs, Integrations
   - Deployment targets: Vercel / GitHub Pages
   - Optional modules clearly marked for phased implementation
   - All frontend architecture decisions must reference **Docusaurus Context 7 MCP**

2. Section Structure:
   - Organize technical work into sections:
     a. Frontend Implementation
        - MDX content pages, responsive design, dark mode, navigation, code blocks
        - Verify all frontend implementation decisions against **Docusaurus Context 7 MCP**
     b. Backend Implementation
        - API design, database structure, session handling, security
     c. Optional Features
        - Feature toggles, experimental modules
   - Each section includes dependencies, tasks, and research notes

3. Research Approach:
   - Use **research-concurrent approach** (research while implementing, not all upfront)
   - Annotate each technical decision with options, tradeoffs, and rationale
   - Follow **APA-style citations** for all sources
   - Include links to official documentation for verification:
     - **Docusaurus Context 7 MCP**: https://docusaurus.io/docs
     - Any other libraries or frameworks used

4. Quality Validation:
   - Map acceptance criteria to technical checks
   - Frontend: responsiveness, accessibility, dark mode, sidebar highlighting
   - Backend: API response time, database constraints, data accuracy
   - Optional: feature-specific tests
   - Include edge-case handling and fallback scenarios

5. Decisions Needing Documentation:
   - UI placement and navigation choices
   - Search implementation: local vs Algolia DocSearch
   - Optional features: scope, toggles, integrations
   - Version control: branching strategy
   - Analytics and monitoring approach

6. Phase Organization:
   - Phase 1: Core MVP ‚Üí Research ‚Üí Foundation ‚Üí Analysis ‚Üí Synthesis
   - Phase 2: Enhanced UX & Features ‚Üí Research ‚Üí Foundation ‚Üí Analysis ‚Üí Synthesis
   - Phase 3: Optional Modules ‚Üí Research ‚Üí Foundation ‚Üí Analysis ‚Üí Synthesis

7. Output:
   - Technical roadmap including architecture diagrams, section-wise tasks, dependencies, and research notes
   - Explicit links to official documentation for verification of all frontend and backend decisions:
     - **Docusaurus Context 7 MCP**: https://docusaurus.io/docs
     - Any other frameworks/libraries used
   - Testing checklist tied to acceptance criteria

## Response snapshot

Created comprehensive 500+ line technical implementation plan for textbook-generation feature:

**Technical Context Established:**
- Frontend: Node.js 18.x/20.x, Docusaurus v3.x, React 18.x
- Backend: Python 3.10+, FastAPI, Sentence Transformers
- Databases: Qdrant Cloud (free tier, <1000 vectors), Neon Postgres (free tier, 512MB)
- Deployment: GitHub Pages/Vercel (frontend), Railway/Render (backend)
- Performance: Lighthouse >90, RAG <2s p95, Build <60s

**Constitution Check: ‚úÖ All Principles Satisfied**
- Simplicity-First: Docusaurus built-ins, no custom frameworks
- Accuracy: RAG grounded in textbook only, confidence thresholds
- Free-Tier: Qdrant <1000 vectors, Neon <512MB, no paid APIs
- Docusaurus Best Practices: All decisions reference https://docusaurus.io/docs
- Minimalism: Single stack (Docusaurus + FastAPI + Qdrant + Neon)
- Fast Builds: <60s target, incremental builds
- Content-First: 6 chapters before advanced features
- RAG Guardrails: >90% accuracy, <3s response, fallback messages

**Project Structure Defined:**
- Frontend: `docs/` (6 chapters, MDX), `src/components/` (ChatbotWidget), `static/` (images)
- Backend: `backend/src/` (FastAPI app, services, API routes), `scripts/` (indexing, migrations)
- Specs: `specs/textbook-generation/` (plan.md, research.md, data-model.md, contracts/, quickstart.md)

**Data Model (5 Entities):**
1. Chapter (id, title, slug, description, metadata) ‚Üí Neon Postgres
2. Section (id, chapter_id, title, heading_level) ‚Üí Neon Postgres
3. ContentChunk (id, chapter_id, text, embedding_vector[384]) ‚Üí Qdrant + Neon metadata
4. ChatSession (session_id, timestamps, message_count) ‚Üí Browser sessionStorage
5. ChatMessage (id, session_id, role, content, source_chunks) ‚Üí Browser sessionStorage

**API Contracts (2 OpenAPI Specs):**
1. `contracts/chatbot-api.yaml`: Public chat API
   - POST /v1/chat (query ‚Üí answer + citations)
   - GET /health (dependency status)
2. `contracts/admin-api.yaml`: Internal indexing API
   - POST /admin/index (re-index content)
   - GET /admin/index/{job_id} (check status)

**Phase 0: Research (7 Tasks, RT-001 to RT-007):**
- RT-001: Docusaurus architecture deep dive (docs-only mode, MDX, theming, deployment)
- RT-002: RAG chunking patterns (chunk size, code vs prose, similarity thresholds)
- RT-003: Sentence Transformers model validation (all-MiniLM-L6-v2 vs alternatives)
- RT-004: Qdrant capacity planning (free tier limits, migration path)
- RT-005: Neon Postgres schema design (minimal metadata, indexing)
- RT-006: Text selection UI patterns (browser API, mobile support, libraries)
- RT-007: Deployment platform comparison (GitHub Pages, Vercel, Railway, Render)

**Research Output Structure:**
- `research.md` with sections for each RT task
- Decision + Rationale + Alternatives + APA citations
- All unknowns from Technical Context resolved

**Phase 1: Foundation (Data Model + Contracts + Quickstart):**
- `data-model.md`: 5 entities with attributes, relationships, validation rules
- `contracts/chatbot-api.yaml`: Full OpenAPI 3.0 spec with schemas
- `contracts/admin-api.yaml`: Internal indexing API spec
- `quickstart.md`: Step-by-step setup for dev environment (frontend + backend)

**System Architecture Diagrams:**
- High-level architecture (browser ‚Üí Docusaurus ‚Üí FastAPI ‚Üí Qdrant/Neon)
- RAG query flow (embed ‚Üí search ‚Üí retrieve ‚Üí generate ‚Üí format)

**Quality Validation Mapping:**
- Frontend: 6 acceptance criteria ‚Üí technical checks (responsive, dark mode, sidebar, code blocks, Lighthouse, build time)
- Backend: 5 acceptance criteria ‚Üí technical checks (response time, search latency, accuracy, confidence, rate limiting)
- Integration: 4 acceptance criteria ‚Üí technical checks (CORS, widget, citations, re-indexing)

**Architectural Decisions Requiring ADRs (3 Identified):**
1. ADR-001: Search provider (local vs Algolia DocSearch)
2. ADR-002: RAG answer generation (raw chunks vs LLM synthesis)
3. ADR-003: Backend deployment platform (Vercel vs Railway vs Render)

**Edge Cases & Fallbacks (5 Scenarios):**
1. Qdrant free tier exceeded ‚Üí increase chunk size, remove low-value chunks, upgrade
2. Neon connection limit ‚Üí connection pooling, proper cleanup, evaluate paid tier
3. Query outside textbook scope ‚Üí similarity <0.5 ‚Üí fallback message
4. JavaScript disabled ‚Üí static HTML readable, chatbot shows JS-required message
5. Code block selection ‚Üí detect <pre> tag ‚Üí pre-fill "Explain this code: [code]"

**Phase Organization (3 Phases):**
- Phase 1 (Weeks 1-4): Core MVP ‚Üí 6 chapters + RAG chatbot + deployment
- Phase 2 (Weeks 5-6): Enhanced UX ‚Üí text selection, progress tracking
- Phase 3 (Weeks 7-8, Optional): Urdu translation + personalized learning paths

**Testing Checklist (45+ Test Cases):**
- P1 User Stories: 15 tests (content, navigation, code examples)
- P2 User Stories: 20 tests (chatbot, search, further resources)
- P3 User Stories: 10 tests (text selection, dark mode)
- P4 User Stories (Optional): 5 tests (Urdu, progress tracking)

**Deliverables:**
- Comprehensive plan.md (500+ lines)
- Clear path to /sp.tasks execution
- All unknowns resolved through research framework
- Constitution compliance verified

## Outcome

- ‚úÖ Impact: Complete technical implementation plan with architecture, data models, API contracts, research framework, quality validation, and phased execution strategy
- üß™ Tests: Testing checklist with 45+ acceptance criteria mapped to technical checks
- üìÅ Files: Created specs/textbook-generation/plan.md (500+ lines)
- üîÅ Next prompts: Execute Phase 0 research (RT-001 to RT-007), create research.md, then run /sp.tasks for task breakdown
- üß† Reflection: Plan thoroughly covers all aspects from specification. Architecture strictly adheres to Docusaurus best practices (Constitution Principle IV). Free-tier constraints carefully planned with fallback strategies. Research-concurrent approach allows iterative refinement during implementation.

## Evaluation notes (flywheel)

- Failure modes observed: none
- Graders run and results (PASS/FAIL): PASS - Comprehensive plan with all required sections, architecture diagrams, API contracts, research tasks, quality validation, and testing checklist
- Prompt variant (if applicable): none
- Next experiment (smallest change to try): Begin Phase 0 research starting with RT-001 (Docusaurus architecture deep dive)
