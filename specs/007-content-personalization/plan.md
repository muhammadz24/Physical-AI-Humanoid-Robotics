# Implementation Plan: Content Personalization

**Branch**: `007-content-personalization` | **Date**: 2025-12-16 | **Spec**: [spec.md](./spec.md)

## Summary

Implement dynamic content personalization for chapter pages based on user's software_experience and hardware_experience levels. Users click a "Personalize This Chapter" button to send chapter content to Gemini LLM, which rewrites the text appropriately for their skill level (beginner gets simpler explanations, expert gets concise technical content). Frontend displays loading state, replaces content, and provides toggle between original and personalized versions. Proof of concept implementation on Chapter 1.

## Technical Context

**Language/Version**: Python 3.11 (backend), JavaScript/React (frontend with Docusaurus)
**Primary Dependencies**: FastAPI, Google Gemini API, React, Docusaurus v3
**Storage**: Client-side session caching (no database persistence for personalized content)
**Testing**: pytest (backend), Jest (frontend)
**Target Platform**: Web application (Vercel/GitHub Pages frontend, backend API)
**Project Type**: Web (backend + frontend)
**Performance Goals**: Personalization completes in <10 seconds, toggle <200ms
**Constraints**: Free-tier Gemini API quota, LLM context limits (~10K words per chapter), session-only caching
**Scale/Scope**: POC on Chapter 1, extendable to all 6 chapters

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

✅ **Principle I (Simplicity-First)**: Feature adds clear pedagogical value by adapting content to user level
✅ **Principle II (Accuracy)**: LLM rewrite preserves technical accuracy (prompt engineering ensures this)
✅ **Principle III (Free-Tier)**: Uses free Google Gemini API within quota limits
✅ **Principle IV (Docusaurus Best Practices)**: Button component integrates via standard Docusaurus patterns
✅ **Principle V (Minimalism)**: No new heavy dependencies, uses existing Gemini integration
✅ **Principle IX (Zero-Edit Deployment)**: API endpoint uses existing environment-agnostic config

**No violations** - all principles satisfied.

## Project Structure

### Documentation (this feature)

```text
specs/007-content-personalization/
├── plan.md              # This file
├── research.md          # Phase 0: LLM prompt engineering research
├── data-model.md        # Phase 1: PersonalizationRequest/Response models
├── quickstart.md        # Phase 1: Setup and testing guide
├── contracts/           # Phase 1: API contract (OpenAPI spec)
│   └── personalize-api.yaml
└── tasks.md             # Phase 2: Generated by /sp.tasks (NOT by /sp.plan)
```

### Source Code (repository root)

```text
backend/
├── app/
│   ├── api/
│   │   ├── personalize.py      # NEW: POST /api/personalize endpoint
│   │   └── auth.py              # EXISTING: Authentication endpoints
│   ├── services/
│   │   ├── llm.py               # EXISTING: Gemini integration (reuse)
│   │   └── user_service.py      # EXISTING: User data retrieval
│   └── models/
│       └── personalize.py       # NEW: PersonalizationRequest/Response models
└── tests/
    └── test_personalize.py      # NEW: Endpoint tests

frontend/src/
├── components/
│   ├── PersonalizeButton/       # NEW: Main personalization UI component
│   │   ├── index.js
│   │   ├── PersonalizeButton.module.css
│   │   └── usePersonalization.js  # Custom hook for API calls and state
│   └── AuthProvider.js          # EXISTING: Auth context
├── utils/
│   └── api.js                   # EXISTING: API utility (add personalize endpoint)
└── pages/
    └── [chapters]/              # MODIFY: Add PersonalizeButton to Chapter 1
```

**Structure Decision**: Web application with existing backend/frontend separation. New personalization logic integrates into existing authentication and LLM services. No new major architectural components needed.

## Complexity Tracking

No violations to justify - feature aligns with all constitutional principles.

## Phase 0: Research

See [research.md](./research.md) for detailed findings on:
- LLM prompt engineering for experience-level adaptation
- Content chunking strategies for long chapters
- Error handling for LLM failures
- Caching strategies (session vs persistent)

## Phase 1: Design

### Data Model

See [data-model.md](./data-model.md) for:
- PersonalizationRequest model
- PersonalizationResponse model
- User experience level schema (already exists from Feature 006)

### API Contracts

See [contracts/personalize-api.yaml](./contracts/personalize-api.yaml) for:
- POST /api/personalize endpoint specification
- Request/response schemas
- Error responses (400, 401, 500, 503)

### Quickstart

See [quickstart.md](./quickstart.md) for:
- Development environment setup
- Testing personalization locally
- Adding PersonalizeButton to new chapters

## Implementation Approach

### Backend

1. **Create Personalization Endpoint** (`backend/app/api/personalize.py`):
   - POST /api/personalize route
   - Extract JWT from request cookies (authentication required)
   - Retrieve user's software_experience and hardware_experience from database
   - Construct LLM prompt with chapter text and user context
   - Call existing Gemini LLM service (reuse `app/services/llm.py`)
   - Return personalized content with 30-second timeout
   - Handle errors gracefully (LLM failure, quota exceeded, timeout)

2. **LLM Prompt Template**:
   ```
   You are an expert educational content adapter. Rewrite the following chapter text to be appropriate for a user with:
   - Software Development Experience: {software_experience}
   - Hardware/Robotics Experience: {hardware_experience}

   Guidelines:
   - For beginners: Use simple language, add explanatory context, include analogies
   - For intermediate: Balanced technical depth, some assumptions of prior knowledge
   - For experts: Concise, technical, advanced concepts, implementation focus
   - Preserve all code blocks, headings, and markdown structure
   - Maintain technical accuracy - do not simplify to the point of incorrectness

   Chapter Text:
   {chapter_content}
   ```

3. **Error Handling**:
   - LLM timeout (30s): Return 503 with retry suggestion
   - Authentication failure: Return 401
   - Invalid input: Return 400 with validation errors
   - Gemini API quota exceeded: Return 503 with clear message
   - Generic errors: Return 500, log for debugging

### Frontend

1. **PersonalizeButton Component** (`src/components/PersonalizeButton/index.js`):
   - Button displayed at top of chapter (conditional on authenticated state)
   - Three states: Idle, Loading, Personalized
   - Idle: "Personalize This Chapter" button visible
   - Loading: Spinner/skeleton, button disabled
   - Personalized: "Show Original" / "Show Personalized" toggle buttons

2. **usePersonalization Hook** (`src/components/PersonalizeButton/usePersonalization.js`):
   - Manages personalization state (original, loading, personalized, error)
   - API call to POST /api/personalize with chapter text
   - Caches personalized content in component state (session-level)
   - Handles errors and provides retry mechanism

3. **Chapter Integration**:
   - Import PersonalizeButton into Chapter 1 MDX file
   - Extract chapter content (use DOM or ref to capture text)
   - Pass content to PersonalizeButton
   - Replace chapter content div with personalized text on success

4. **UI/UX**:
   - Loading indicator: "Personalizing content for your experience level..."
   - Error message: "Failed to personalize. [Retry]" button
   - Toggle: Smooth transition between original and personalized (no API call)
   - Responsive design (works on mobile)

### Testing Strategy

**Backend**:
- Unit tests for personalization endpoint
- Test with different experience level combinations
- Test authentication enforcement
- Test LLM timeout handling
- Test error cases (invalid input, quota exceeded)

**Frontend**:
- Component tests for PersonalizeButton states
- Integration test for full flow (click → API → content replacement)
- Test toggle functionality
- Test error handling and retry

**Manual Testing**:
- Test as beginner user on Chapter 1
- Test as expert user on Chapter 1
- Test error scenarios (backend down, LLM timeout)
- Test toggle between original and personalized

## Security Considerations

- **Authentication required**: Personalization only for logged-in users (prevents quota abuse)
- **Input validation**: Sanitize chapter text before sending to LLM
- **Rate limiting**: Consider adding rate limiting to /api/personalize (e.g., 10 requests/hour per user)
- **Content validation**: Ensure LLM response doesn't contain malicious content (basic sanitization)

## Deployment Notes

- **Environment Variables**: No new env vars required (uses existing GEMINI_API_KEY)
- **Database**: No schema changes (uses existing users table for experience levels)
- **Rollout**: POC on Chapter 1 first, expand to other chapters after validation
- **Monitoring**: Track personalization success rate, LLM response times, quota usage

## Future Enhancements (Out of Scope)

- Persistent storage of personalized content in database
- Feedback mechanism (thumbs up/down on personalization quality)
- Multiple personalization styles (concise, detailed, visual)
- Automatic personalization (no button click)
- Personalization for non-chapter content (docs, guides)
- A/B testing different LLM prompts
- Analytics on which experience levels use personalization most

## Phase 2: Task Generation

Use `/sp.tasks` command to generate tasks.md from this plan and the specification.

## Artifacts

- [x] plan.md (this file)
- [x] research.md (Phase 0)
- [x] data-model.md (Phase 1)
- [x] contracts/personalize-api.yaml (Phase 1)
- [x] quickstart.md (Phase 1)
- [ ] tasks.md (Phase 2 - run /sp.tasks)
